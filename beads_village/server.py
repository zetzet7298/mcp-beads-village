"""Beads Village MCP - Multi-agent workflow with Beads + Agent Mail.

Combines:
- Beads (Steve Yegge): Git-native issue tracker for AI agents
- Agent Mail concepts: File reservations + messaging for coordination

Best practices from https://steve-yegge.medium.com/beads-best-practices-2db636b9760c
"""

import asyncio
import hashlib
import json
import os
import subprocess
import sys
import tempfile
import uuid
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Optional, Set, List, Any

# Daemon client for faster operations (optional)
from .bd_daemon_client import BdDaemonClient, is_daemon_available, DaemonError, DaemonNotRunningError

# ============================================================================
# CONFIG
# ============================================================================

AGENT = os.environ.get("BEADS_AGENT", f"agent-{os.getpid()}")

# Current workspace - can be changed via init(ws=...)
# Each workspace has its own .beads/, .mail/, .reservations/
WS = os.environ.get("BEADS_WS", os.getcwd())

# Team/Project identifier - groups related workspaces together
# Agents in the same team can see each other's broadcasts
# Different teams are completely isolated
# Default: "default" (all agents in same team)
# Can be changed via init(team=...) at runtime
TEAM = os.environ.get("BEADS_TEAM", "default")

# Base directory for all team data
BEADS_VILLAGE_BASE = os.environ.get(
    "BEADS_VILLAGE_BASE",
    os.path.join(os.path.expanduser("~"), ".beads-village")
)

# Global mail hub - shared across workspaces IN THE SAME TEAM
# Default: ~/.beads-village/{team}/mail
def _get_team_mail_dir(team: str = None):
    """Get mail directory for a team."""
    t = team or TEAM
    return os.path.join(BEADS_VILLAGE_BASE, t, "mail")

# Agent registry - tracks active agents IN THE SAME TEAM
def _get_team_registry_dir(team: str = None):
    """Get agent registry directory for a team."""
    t = team or TEAM
    return os.path.join(BEADS_VILLAGE_BASE, t, "agents")

def get_available_teams() -> List[str]:
    """List all available teams (directories in ~/.beads-village/)."""
    teams = []
    if os.path.isdir(BEADS_VILLAGE_BASE):
        for name in os.listdir(BEADS_VILLAGE_BASE):
            team_dir = os.path.join(BEADS_VILLAGE_BASE, name)
            if os.path.isdir(team_dir):
                teams.append(name)
    return sorted(teams)

# Prefer daemon over CLI for faster operations (set BEADS_USE_DAEMON=0 to disable)
USE_DAEMON = os.environ.get("BEADS_USE_DAEMON", "1") == "1"

# Daemon client instance (lazy initialized)
_daemon_client: Optional[BdDaemonClient] = None

# ============================================================================
# STATE
# ============================================================================

@dataclass
class State:
    """Agent session state."""
    issue: Optional[str] = None
    start: datetime = field(default_factory=datetime.now)
    done: int = 0
    reserved_files: Set[str] = field(default_factory=set)

S = State()

# ============================================================================
# HELPERS
# ============================================================================

def bd_sync(*args, timeout: float = 30.0) -> dict:
    """Run bd CLI command synchronously.
    
    Runs in current WS directory - each workspace has its own beads database.
    """
    try:
        cmd = ["bd", *args]
        # Add --json if command supports it and not already present
        json_cmds = {"list", "ready", "show", "stats", "doctor", "cleanup", "create"}
        if args and args[0] in json_cmds and "--json" not in args:
            cmd.append("--json")
        
        # Run bd in current workspace
        result = subprocess.run(
            cmd,
            capture_output=True,
            timeout=timeout,
            cwd=WS,
        )
        if result.returncode != 0:
            stderr = result.stderr.decode()[:200] if result.stderr else ""
            return {"error": stderr or "command failed"}
        
        stdout = result.stdout.decode().strip() if result.stdout else ""
        if not stdout:
            return {"ok": 1}
        
        try:
            return json.loads(stdout)
        except json.JSONDecodeError:
            return {"output": stdout}
    except subprocess.TimeoutExpired:
        return {"error": "timeout"}
    except FileNotFoundError:
        return {"error": "bd CLI not found - install beads first"}
    except Exception as e:
        return {"error": str(e)[:100]}


def _get_daemon_client() -> Optional[BdDaemonClient]:
    """Get or create daemon client for current workspace.
    
    Returns:
        BdDaemonClient if daemon is available and enabled, None otherwise
    """
    global _daemon_client
    
    if not USE_DAEMON:
        return None
    
    if not is_daemon_available(WS):
        return None
    
    if _daemon_client is None or _daemon_client.working_dir != WS:
        _daemon_client = BdDaemonClient(working_dir=WS, actor=AGENT)
    
    return _daemon_client


async def bd(*args, timeout: float = 30.0) -> dict:
    """Run bd command - uses daemon if available, falls back to CLI.
    
    The daemon is ~10x faster than CLI for repeated operations.
    """
    # Try daemon first if enabled
    daemon = _get_daemon_client()
    if daemon:
        try:
            return await _bd_via_daemon(daemon, args)
        except (DaemonError, DaemonNotRunningError):
            # Fall back to CLI
            pass
    
    # Fall back to CLI
    return bd_sync(*args, timeout=timeout)


async def _bd_via_daemon(daemon: BdDaemonClient, args: tuple) -> dict:
    """Execute bd command via daemon client.
    
    Maps CLI-style args to daemon RPC calls.
    """
    if not args:
        return {"error": "no command specified"}
    
    cmd = args[0]
    
    if cmd == "init":
        # Init doesn't go through daemon
        raise DaemonNotRunningError("init must use CLI")
    
    elif cmd == "ready":
        limit = 5
        # Parse --limit from args
        for i, arg in enumerate(args):
            if arg == "--limit" and i + 1 < len(args):
                try:
                    limit = int(args[i + 1])
                except ValueError:
                    pass
        
        issues = await daemon.ready(limit=limit)
        return issues if isinstance(issues, list) else [issues] if issues else []
    
    elif cmd == "list":
        status = None
        limit = 10
        for i, arg in enumerate(args):
            if arg == "--status" and i + 1 < len(args):
                status = args[i + 1]
            elif arg == "--limit" and i + 1 < len(args):
                try:
                    limit = int(args[i + 1])
                except ValueError:
                    pass
        
        issues = await daemon.list_issues(status=status, limit=limit)
        return issues if isinstance(issues, list) else [issues] if issues else []
    
    elif cmd == "show" and len(args) > 1:
        issue_id = args[1]
        return await daemon.show(issue_id)
    
    elif cmd == "create":
        # Parse create args
        title = args[1] if len(args) > 1 else ""
        issue_type = "task"
        priority = 2
        description = ""
        deps = []
        
        i = 2
        while i < len(args):
            arg = args[i]
            if arg in ("-t", "--type") and i + 1 < len(args):
                issue_type = args[i + 1]
                i += 2
            elif arg in ("-p", "--priority") and i + 1 < len(args):
                try:
                    priority = int(args[i + 1])
                except ValueError:
                    pass
                i += 2
            elif arg in ("-d", "--description") and i + 1 < len(args):
                description = args[i + 1]
                i += 2
            elif arg == "--deps" and i + 1 < len(args):
                deps.append(args[i + 1])
                i += 2
            elif arg == "--json":
                i += 1  # Skip
            else:
                i += 1
        
        return await daemon.create(
            title=title,
            issue_type=issue_type,
            priority=priority,
            description=description,
            deps=deps if deps else None,
        )
    
    elif cmd == "update" and len(args) > 1:
        issue_id = args[1]
        status = None
        priority = None
        
        for i, arg in enumerate(args):
            if arg == "--status" and i + 1 < len(args):
                status = args[i + 1]
            elif arg in ("-p", "--priority") and i + 1 < len(args):
                try:
                    priority = int(args[i + 1])
                except ValueError:
                    pass
        
        return await daemon.update(issue_id, status=status, priority=priority)
    
    elif cmd == "close" and len(args) > 1:
        issue_id = args[1]
        reason = "Completed"
        for i, arg in enumerate(args):
            if arg == "--reason" and i + 1 < len(args):
                reason = args[i + 1]
        
        return await daemon.close(issue_id, reason=reason)
    
    elif cmd == "sync":
        return await daemon.sync()
    
    elif cmd == "stats":
        return await daemon.stats()
    
    elif cmd == "dep" and len(args) > 3 and args[1] == "add":
        from_id = args[2]
        to_id = args[3]
        dep_type = "blocks"
        for i, arg in enumerate(args):
            if arg == "--type" and i + 1 < len(args):
                dep_type = args[i + 1]
        
        await daemon.add_dependency(from_id, to_id, dep_type)
        return {"ok": 1}
    
    else:
        # Command not supported by daemon, fall back to CLI
        raise DaemonNotRunningError(f"Command '{cmd}' not supported by daemon")


def ensure_dir(base: str, name: str) -> str:
    """Ensure directory exists and return path."""
    d = os.path.join(base, name)
    os.makedirs(d, exist_ok=True)
    return d


def global_mail_dir() -> str:
    """Global mail directory - shared across ALL workspaces IN CURRENT TEAM.
    
    Messages sent here are visible to agents in any workspace within the team.
    Used for cross-workspace coordination.
    """
    d = _get_team_mail_dir(TEAM)
    os.makedirs(d, exist_ok=True)
    return d


def agent_registry_dir() -> str:
    """Agent registry directory - tracks active agents IN CURRENT TEAM.
    
    Each agent registers with: agent_id, workspace, capabilities, last_seen.
    """
    d = _get_team_registry_dir(TEAM)
    os.makedirs(d, exist_ok=True)
    return d


def mail_dir() -> str:
    """Mail directory - in current workspace."""
    return ensure_dir(WS, ".mail")


def reservation_dir() -> str:
    """Reservation directory - in current workspace."""
    return ensure_dir(WS, ".reservations")


def j(data: Any) -> str:
    """Compact JSON serialization."""
    return json.dumps(data, separators=(',', ':'), ensure_ascii=False)


def path_hash(path: str) -> str:
    """Generate short hash for file path."""
    return hashlib.sha1(path.encode()).hexdigest()[:12]


def to_posix_path(path: str) -> str:
    """Convert path to POSIX format (forward slashes) for cross-platform consistency."""
    return path.replace("\\", "/")


def normalize_path(path: str) -> str:
    """Normalize and validate path is within workspace.
    
    Prevents path traversal attacks by ensuring path stays within WS.
    Returns relative path in POSIX format (forward slashes) for cross-platform consistency.
    
    Raises:
        ValueError: If path is outside workspace
    """
    clean_path = path.replace("\\", "/")
    
    if os.path.isabs(clean_path):
        abs_path = os.path.normpath(clean_path)
    else:
        abs_path = os.path.normpath(os.path.join(WS, clean_path))
    
    ws_abs = os.path.abspath(WS)
    
    if not (abs_path.startswith(ws_abs + os.sep) or abs_path == ws_abs):
        raise ValueError(f"Path outside workspace: {path}")
    
    rel_path = os.path.relpath(abs_path, WS)
    return to_posix_path(rel_path)


def try_atomic_reserve(path: str, reservation: dict) -> tuple:
    """Atomically try to create reservation file.
    
    Uses temp file + rename pattern for atomicity.
    On Windows, os.replace() is used which is atomic.
    
    Returns:
        (success: bool, existing_reservation: Optional[dict])
    """
    res_file = os.path.join(reservation_dir(), f"{path_hash(path)}.json")
    now = datetime.now()
    
    if os.path.exists(res_file):
        try:
            with open(res_file, encoding="utf-8") as f:
                existing = json.load(f)
            if datetime.fromisoformat(existing["expires"]) > now:
                if existing["agent"] != AGENT:
                    return False, existing
        except (json.JSONDecodeError, OSError, KeyError, ValueError):
            pass
    
    fd = None
    tmp_path = None
    try:
        fd, tmp_path = tempfile.mkstemp(dir=reservation_dir(), suffix=".tmp")
        with os.fdopen(fd, 'w', encoding="utf-8") as f:
            fd = None
            json.dump(reservation, f)
        
        os.replace(tmp_path, res_file)
        tmp_path = None
        return True, None
    except OSError:
        return False, None
    finally:
        if fd is not None:
            try:
                os.close(fd)
            except OSError:
                pass
        if tmp_path and os.path.exists(tmp_path):
            try:
                os.unlink(tmp_path)
            except OSError:
                pass


# ============================================================================
# MAIL FUNCTIONS
# ============================================================================

async def send_msg(subj: str, body: str = "", to: str = "all", 
                   thread_id: str = "", importance: str = "normal",
                   global_broadcast: bool = False) -> dict:
    """Send message to other agents.
    
    Args:
        subj: Message subject
        body: Message body
        to: Recipient ('all' for broadcast, or specific agent ID)
        thread_id: Thread ID for grouping messages
        importance: 'low', 'normal', or 'high'
        global_broadcast: If True, send to global mail hub (visible to ALL agents across ALL workspaces)
    """
    msg = {
        "f": AGENT,
        "t": to,
        "s": subj,
        "b": body,
        "ts": datetime.now().isoformat(),
        "thread": thread_id or S.issue or "",
        "imp": importance,
        "issue": S.issue,
        "ws": WS,  # Include source workspace
    }
    ts = datetime.now().timestamp()
    unique = uuid.uuid4().hex[:6]
    
    # Choose directory: local workspace or global hub
    target_dir = global_mail_dir() if global_broadcast else mail_dir()
    p = os.path.join(target_dir, f"{ts:.6f}_{unique}.json")
    
    with open(p, "w", encoding="utf-8") as f:
        json.dump(msg, f)
    
    return {"sent": 1, "global": global_broadcast}


async def recv_msgs(n: int = 5, unread_only: bool = False, 
                    include_global: bool = True) -> List[dict]:
    """Receive messages from other agents.
    
    Args:
        n: Maximum messages to return
        unread_only: Only return unread messages
        include_global: Also check global mail hub for cross-workspace messages
    """
    msgs = []
    
    # Collect from directories
    dirs_to_check = [mail_dir()]
    if include_global:
        dirs_to_check.append(global_mail_dir())
    
    for d in dirs_to_check:
        read_file = os.path.join(d, f".read_{AGENT}")
        read_ts = 0.0
        
        if os.path.exists(read_file):
            try:
                with open(read_file, encoding="utf-8") as f:
                    read_ts = float(f.read().strip())
            except (OSError, ValueError):
                read_ts = 0.0
        
        try:
            files = sorted(os.listdir(d))
            for fname in files[-50:]:
                if not fname.endswith(".json") or fname.startswith("."):
                    continue
                try:
                    fp = os.path.join(d, fname)
                    with open(fp, encoding="utf-8") as file:
                        m = json.load(file)
                    
                    if m.get("t") not in ["all", AGENT]:
                        continue
                    
                    if unread_only:
                        ts_part = fname.replace(".json", "").split("_")[0]
                        try:
                            file_ts = float(ts_part)
                            if file_ts <= read_ts:
                                continue
                        except ValueError:
                            pass
                    
                    # Mark if from global hub
                    if d == global_mail_dir():
                        m["_global"] = True
                    
                    msgs.append(m)
                except (json.JSONDecodeError, OSError):
                    pass
        except OSError:
            pass
        
        # Update read timestamp for this directory
        if msgs:
            try:
                with open(read_file, "w", encoding="utf-8") as f:
                    f.write(str(datetime.now().timestamp()))
            except OSError:
                pass
    
    # Sort by timestamp and return last n
    msgs.sort(key=lambda x: x.get("ts", ""))
    return msgs[-n:]


# ============================================================================
# AGENT REGISTRY FUNCTIONS
# ============================================================================

def register_agent(capabilities: List[str] = None) -> dict:
    """Register this agent in the team registry.
    
    Other agents in the same team can discover us and see what workspace we're in.
    """
    reg_file = os.path.join(agent_registry_dir(), f"{AGENT}.json")
    
    registration = {
        "agent": AGENT,
        "ws": WS,
        "team": TEAM,
        "capabilities": capabilities or ["general"],
        "registered": datetime.now().isoformat(),
        "last_seen": datetime.now().isoformat(),
    }
    
    with open(reg_file, "w", encoding="utf-8") as f:
        json.dump(registration, f)
    
    return registration


def update_agent_heartbeat() -> None:
    """Update last_seen timestamp for this agent."""
    reg_file = os.path.join(agent_registry_dir(), f"{AGENT}.json")
    
    if os.path.exists(reg_file):
        try:
            with open(reg_file, encoding="utf-8") as f:
                reg = json.load(f)
            reg["last_seen"] = datetime.now().isoformat()
            with open(reg_file, "w", encoding="utf-8") as f:
                json.dump(reg, f)
        except (json.JSONDecodeError, OSError):
            pass


def get_active_agents(max_age_minutes: int = 30) -> List[dict]:
    """Get list of active agents across all workspaces.
    
    Args:
        max_age_minutes: Consider agent inactive if not seen within this time
    """
    agents = []
    cutoff = datetime.now() - timedelta(minutes=max_age_minutes)
    
    try:
        for fname in os.listdir(agent_registry_dir()):
            if not fname.endswith(".json"):
                continue
            try:
                with open(os.path.join(agent_registry_dir(), fname), encoding="utf-8") as f:
                    reg = json.load(f)
                last_seen = datetime.fromisoformat(reg.get("last_seen", "2000-01-01"))
                if last_seen > cutoff:
                    agents.append(reg)
            except (json.JSONDecodeError, OSError, ValueError):
                pass
    except OSError:
        pass
    
    return agents


def discover_workspaces() -> List[dict]:
    """Discover all workspaces from registered agents in the same team.
    
    Returns unique workspaces with their active agent counts.
    """
    agents = get_active_agents()
    ws_map = {}
    
    for agent in agents:
        ws = agent.get("ws", "")
        if ws:
            if ws not in ws_map:
                ws_map[ws] = {"ws": ws, "agents": [], "count": 0, "team": TEAM}
            ws_map[ws]["agents"].append(agent.get("agent", "unknown"))
            ws_map[ws]["count"] += 1
    
    return list(ws_map.values())


# ============================================================================
# RESERVATION FUNCTIONS
# ============================================================================

def cleanup_expired_reservations():
    """Remove expired reservations."""
    now = datetime.now()
    d = reservation_dir()
    cleaned = 0
    
    try:
        for fname in os.listdir(d):
            if not fname.endswith(".json"):
                continue
            fp = os.path.join(d, fname)
            try:
                with open(fp, encoding="utf-8") as file:
                    res = json.load(file)
                if datetime.fromisoformat(res["expires"]) < now:
                    os.remove(fp)
                    cleaned += 1
            except (json.JSONDecodeError, OSError, KeyError, ValueError):
                pass
    except OSError:
        pass
    
    return cleaned


def get_active_reservations() -> List[dict]:
    """Get all active (non-expired) reservations."""
    cleanup_expired_reservations()
    now = datetime.now()
    d = reservation_dir()
    active = []
    
    try:
        for fname in os.listdir(d):
            if not fname.endswith(".json"):
                continue
            try:
                with open(os.path.join(d, fname), encoding="utf-8") as fp:
                    res = json.load(fp)
                if datetime.fromisoformat(res["expires"]) > now:
                    active.append(res)
            except (json.JSONDecodeError, OSError, KeyError, ValueError):
                pass
    except OSError:
        pass
    
    return active


def check_reservation_conflict(path: str) -> Optional[dict]:
    """Check if path conflicts with existing reservation."""
    cleanup_expired_reservations()
    now = datetime.now()
    res_file = os.path.join(reservation_dir(), f"{path_hash(path)}.json")
    
    if os.path.exists(res_file):
        try:
            with open(res_file, encoding="utf-8") as f:
                existing = json.load(f)
            if datetime.fromisoformat(existing["expires"]) > now:
                if existing["agent"] != AGENT:
                    return existing
        except (json.JSONDecodeError, OSError, KeyError, ValueError):
            pass
    
    return None


# ============================================================================
# TOOL IMPLEMENTATIONS
# ============================================================================

async def tool_init(args: dict) -> str:
    """Initialize/join a beads workspace with actionable errors.

    Each workspace (BE/FE/Mobile) has its own isolated:
    - .beads/ (task database)
    - .mail/ (messages between agents in this workspace)
    - .reservations/ (file locks)

    Args:
        ws: Workspace directory to join. Each workspace is independent.
        team: Team/project name to join. Can switch teams at runtime.
    """
    global WS, TEAM

    # Switch to specified workspace
    if args.get("ws"):
        WS = os.path.abspath(args["ws"])

    # Switch to specified team (allows runtime team switching!)
    if args.get("team"):
        TEAM = args["team"]

    # Ensure workspace directory exists
    if not os.path.isdir(WS):
        # List available teams as hint
        available_teams = get_available_teams()
        return j({
            "error": f"workspace not found: {WS}",
            "hint": "Provide a valid directory path with ws parameter, or ensure current directory exists.",
            "available_teams": available_teams
        })

    # Init beads in this workspace
    result = await bd("init")
    if result.get("error"):
        err_msg = str(result.get("error", ""))
        if "already" not in err_msg.lower():
            return j({
                "error": err_msg,
                "hint": "Ensure 'bd' CLI is installed: go install github.com/steveyegge/beads/cmd/bd@latest"
            })

    # Ensure mail and reservation dirs
    mail_dir()
    reservation_dir()

    # Clean up any expired reservations
    cleanup_expired_reservations()
    
    # Register agent in global registry (for cross-workspace discovery)
    register_agent(capabilities=["general"])

    # Announce agent joining this workspace (local)
    await send_msg("join", f"Agent {AGENT} joined workspace {WS}")
    
    # Also announce globally so other workspaces know
    await send_msg("join", f"Agent {AGENT} joined workspace {WS}", global_broadcast=True)

    # Get available teams for user reference
    available_teams = get_available_teams()

    return j({
        "ok": 1,
        "agent": AGENT,
        "ws": WS,
        "team": TEAM,
        "available_teams": available_teams,
        "hint": "Workspace ready. Use 'claim' to get a task, or 'ready' to see available tasks."
    })


async def tool_claim(_args: dict) -> str:
    """Claim next ready task (highest priority first) with actionable errors."""
    # Sync first to get latest state
    await bd("sync")

    # Get ready issues
    r = await bd("ready")

    if isinstance(r, dict) and r.get("error"):
        return j({
            "error": r["error"],
            "hint": "Run 'init' first to initialize workspace, or 'doctor' to fix issues."
        })

    if not r or (isinstance(r, list) and len(r) == 0):
        return j({
            "ok": 0,
            "msg": "no ready tasks",
            "hint": "No tasks available to claim. Use 'add' to create new tasks, or 'ls' to see all issues."
        })

    # Get first ready issue
    issue = r[0] if isinstance(r, list) else r
    issue_id = issue.get("id", "")

    # Update status (agents claim, not assigned per Steve's article)
    await bd("update", issue_id, "--status", "in_progress")

    # Track in session state
    S.issue = issue_id

    # Notify other agents
    await send_msg(f"claimed:{issue_id}", issue.get("title", ""), importance="high")

    return j({
        "id": issue_id,
        "t": issue.get("title", ""),
        "p": issue.get("priority", 2),
        "s": "in_progress",
        "hint": "Task claimed. Use 'reserve' before editing files, then 'done' when complete."
    })


async def tool_done(args: dict) -> str:
    """Close task and sync with actionable errors."""
    issue_id = args.get("id", S.issue)
    if not issue_id:
        return j({
            "error": "no issue id",
            "hint": "Provide an issue ID, or use 'claim' first to set current task."
        })

    msg = args.get("msg", "completed")

    # Close issue
    r = await bd("close", issue_id, "--reason", msg)
    if isinstance(r, dict) and r.get("error"):
        return j({
            "error": r["error"],
            "hint": f"Failed to close issue '{issue_id}'. Use 'show' to verify issue exists."
        })

    # Release any file reservations
    if S.reserved_files:
        for path in list(S.reserved_files):
            res_file = os.path.join(reservation_dir(), f"{path_hash(path)}.json")
            if os.path.exists(res_file):
                try:
                    os.remove(res_file)
                except Exception:
                    pass
        S.reserved_files.clear()

    # Sync to share with other agents
    await bd("sync")

    # Notify
    await send_msg(f"done:{issue_id}", msg, importance="high")

    S.issue = None
    S.done += 1

    return j({
        "ok": 1,
        "done": S.done,
        "hint": "Task completed. Restart session for best performance (1 task = 1 session pattern)."
    })


async def tool_add(args: dict) -> str:
    """Create new issue (file issues for anything >2 min) with actionable errors.
    
    IMPORTANT: Always provide a meaningful description with context about:
    - Why this issue exists (problem statement or need)
    - What needs to be done (scope and approach)
    - How you discovered it (if applicable)
    """
    title = args.get("title", "")
    if not title:
        return j({
            "error": "title required",
            "hint": "Provide a clear, actionable title. Example: 'Fix login timeout on slow networks'"
        })

    typ = args.get("typ", "task")
    if typ not in ("task", "bug", "feature", "epic", "chore"):
        return j({
            "error": f"invalid type: {typ}",
            "hint": "Valid types: 'task' (default), 'bug', 'feature', 'epic', 'chore'"
        })

    pri = args.get("pri", 2)
    if not isinstance(pri, int) or pri < 0 or pri > 4:
        return j({
            "error": f"invalid priority: {pri}",
            "hint": "Priority must be 0-4. 0=critical, 1=high, 2=normal (default), 3=low, 4=backlog"
        })

    description = args.get("desc", "")
    deps = args.get("deps", [])
    parent = args.get("parent", S.issue)  # Default to current issue

    # Build command arguments
    cmd_args = ["create", title, "-t", typ, "-p", str(pri), "--json"]
    
    # Add description if provided
    if description:
        cmd_args.extend(["--description", description])
    
    # Add dependencies if provided (format: "discovered-from:bd-123" or just "bd-123")
    if deps:
        for dep in deps:
            cmd_args.extend(["--deps", dep])
    
    # Create issue
    r = await bd(*cmd_args)

    if isinstance(r, dict) and r.get("error"):
        return j({
            "error": r["error"],
            "hint": "Failed to create issue. Run 'init' to initialize workspace first."
        })

    new_id = r.get("id", "")

    if not new_id:
        return j({
            "error": "failed to create issue",
            "details": r,
            "hint": "Check if workspace is initialized with 'status'"
        })

    # Link to parent if specified and no deps provided (for backward compatibility)
    if parent and new_id and not deps:
        await bd("dep", "add", new_id, parent, "--type", "discovered-from")

    return j({
        "id": new_id,
        "t": title,
        "p": pri,
        "typ": typ,
        "desc": description[:100] + "..." if len(description) > 100 else description,
        "parent": parent if not deps else None,
        "deps": deps,
        "hint": f"Issue created. Use 'show {new_id}' to see details."
    })


async def tool_ls(args: dict) -> str:
    """List issues with pagination."""
    status = args.get("status", "open")
    limit = min(args.get("limit", 10), 50)  # Cap at 50
    offset = args.get("offset", 0)

    r = await bd("list", "--status", status)

    if isinstance(r, dict) and r.get("error"):
        return j({
            "error": r["error"],
            "hint": "Try running 'doctor' to fix database issues, or 'init' to initialize workspace"
        })

    if not isinstance(r, list):
        return j({
            "items": [],
            "total": 0,
            "count": 0,
            "offset": offset,
            "has_more": False
        })

    total = len(r)
    paginated = r[offset:offset + limit]

    items = [{
        "id": i.get("id", ""),
        "t": i.get("title", ""),
        "p": i.get("priority", 2),
        "s": i.get("status", "")
    } for i in paginated]

    return j({
        "items": items,
        "total": total,
        "count": len(items),
        "offset": offset,
        "has_more": offset + limit < total,
        "next_offset": offset + limit if offset + limit < total else None
    })


async def tool_ready(args: dict) -> str:
    """Get ready issues (no blockers) with pagination."""
    limit = min(args.get("limit", 5), 20)  # Cap at 20

    r = await bd("ready")

    if isinstance(r, dict) and r.get("error"):
        return j({
            "error": r["error"],
            "hint": "Try running 'sync' to fetch latest state, or 'doctor' to fix issues"
        })

    if not isinstance(r, list):
        return j({
            "items": [],
            "total": 0,
            "count": 0,
            "has_more": False
        })

    total = len(r)
    paginated = r[:limit]

    items = [{
        "id": i.get("id", ""),
        "t": i.get("title", ""),
        "p": i.get("priority", 2)
    } for i in paginated]

    return j({
        "items": items,
        "total": total,
        "count": len(items),
        "has_more": limit < total
    })


async def tool_show(args: dict) -> str:
    """Get issue details with actionable error messages."""
    issue_id = args.get("id", "")
    if not issue_id:
        return j({
            "error": "id required",
            "hint": "Provide an issue ID. Use 'ls' or 'ready' to find available issues."
        })

    r = await bd("show", issue_id)

    if isinstance(r, dict) and r.get("error"):
        return j({
            "error": r["error"],
            "hint": f"Issue '{issue_id}' not found. Use 'ls' to list available issues."
        })

    return j(r)


async def tool_cleanup(args: dict) -> str:
    """Cleanup old closed issues (run every few days)."""
    days = args.get("days", 2)
    
    r = await bd("cleanup", "--days", str(days))
    await bd("sync")
    
    return j({
        "ok": 1,
        "days": days,
        "cleaned": r.get("deleted", r.get("cleaned", 0))
    })


async def tool_doctor(_args: dict) -> str:
    """Check and fix beads health."""
    r = await bd("doctor", "--fix")
    return j(r)


async def tool_sync(_args: dict) -> str:
    """Sync beads with git."""
    r = await bd("sync")
    return j({"ok": 1, "result": r})


# ============================================================================
# FILE RESERVATION TOOLS
# ============================================================================

async def tool_reserve(args: dict) -> str:
    """Reserve files/paths for exclusive editing.
    
    Use this before editing files to prevent conflicts with other agents.
    Reservations expire after TTL seconds.
    Uses atomic file creation to prevent race conditions.
    """
    paths = args.get("paths", [])
    if isinstance(paths, str):
        paths = [paths]
    
    if not paths:
        return j({"error": "paths required", "hint": "Provide list of file paths to reserve"})
    
    ttl = args.get("ttl", 600)
    reason = args.get("reason", S.issue or "editing")
    
    conflicts = []
    grants = []
    errors = []
    now = datetime.now()
    expires = now + timedelta(seconds=ttl)
    
    for path in paths:
        try:
            normalized = normalize_path(path)
        except ValueError as e:
            errors.append({"path": path, "error": str(e)})
            continue
        
        reservation = {
            "path": normalized,
            "agent": AGENT,
            "reason": reason,
            "created": now.isoformat(),
            "expires": expires.isoformat()
        }
        
        success, existing = try_atomic_reserve(normalized, reservation)
        
        if success:
            grants.append(normalized)
            S.reserved_files.add(normalized)
        elif existing:
            conflicts.append({
                "path": normalized,
                "holder": existing["agent"],
                "reason": existing.get("reason", ""),
                "expires": existing["expires"]
            })
        else:
            errors.append({"path": normalized, "error": "failed to reserve"})
    
    result = {
        "granted": grants,
        "conflicts": conflicts,
        "expires": expires.isoformat() if grants else None
    }
    if errors:
        result["errors"] = errors
    
    return j(result)


async def tool_release(args: dict) -> str:
    """Release file reservations."""
    paths = args.get("paths", [])
    
    if not paths:
        paths = list(S.reserved_files)
    
    if isinstance(paths, str):
        paths = [paths]
    
    released = []
    
    for path in paths:
        try:
            normalized = normalize_path(path)
        except ValueError:
            normalized = path
        
        res_file = os.path.join(reservation_dir(), f"{path_hash(normalized)}.json")
        if os.path.exists(res_file):
            try:
                with open(res_file, encoding="utf-8") as f:
                    res = json.load(f)
                if res.get("agent") == AGENT:
                    os.remove(res_file)
                    released.append(normalized)
            except (json.JSONDecodeError, OSError):
                pass
        S.reserved_files.discard(path)
        S.reserved_files.discard(normalized)
    
    return j({"released": released})


async def tool_reservations(_args: dict) -> str:
    """List active file reservations."""
    active = get_active_reservations()
    
    items = [{
        "path": r.get("path", ""),
        "agent": r.get("agent", ""),
        "reason": r.get("reason", ""),
        "expires": r.get("expires", "")
    } for r in active]
    
    return j(items)


# ============================================================================
# MESSAGING TOOLS
# ============================================================================

async def tool_msg(args: dict) -> str:
    """Send message to other agents."""
    subj = args.get("subj", "")
    if not subj:
        return j({"error": "subj required"})
    
    body = args.get("body", "")
    to = args.get("to", "all")
    thread_id = args.get("thread", S.issue or "")
    importance = args.get("importance", "normal")
    global_broadcast = args.get("global", False)
    
    result = await send_msg(subj, body, to, thread_id, importance, global_broadcast)
    
    return j({"ok": 1, "global": global_broadcast})


async def tool_inbox(args: dict) -> str:
    """Get messages from other agents."""
    n = args.get("n", 5)
    unread = args.get("unread", False)
    include_global = args.get("global", True)  # Default: include global messages
    
    msgs = await recv_msgs(n, unread, include_global)
    
    items = [{
        "f": m.get("f", ""),
        "s": m.get("s", ""),
        "b": m.get("b", "")[:100],
        "ts": m.get("ts", ""),
        "imp": m.get("imp", "normal"),
        "ws": m.get("ws", ""),  # Source workspace
        "global": m.get("_global", False),  # Is from global hub
    } for m in msgs]
    
    return j(items)


async def tool_broadcast(args: dict) -> str:
    """Broadcast message to ALL agents across ALL workspaces.
    
    Use this for important announcements that all agents need to see,
    regardless of which workspace they're in.
    """
    subj = args.get("subj", "")
    if not subj:
        return j({"error": "subj required"})
    
    body = args.get("body", "")
    importance = args.get("importance", "high")  # Default high for broadcasts
    
    result = await send_msg(subj, body, "all", S.issue or "", importance, global_broadcast=True)
    
    return j({"ok": 1, "broadcast": True, "hint": "Message sent to all agents in team"})


async def tool_discover(_args: dict) -> str:
    """Discover all active agents and workspaces in the same team.
    
    Returns list of active agents with their workspaces, useful for
    cross-workspace coordination within your team/project.
    """
    # Update our heartbeat
    update_agent_heartbeat()
    
    agents = get_active_agents()
    workspaces = discover_workspaces()
    
    return j({
        "team": TEAM,
        "agents": [{
            "agent": a.get("agent", ""),
            "ws": a.get("ws", ""),
            "capabilities": a.get("capabilities", []),
            "last_seen": a.get("last_seen", ""),
        } for a in agents],
        "workspaces": workspaces,
        "total_agents": len(agents),
        "total_workspaces": len(workspaces),
    })


async def tool_status(_args: dict) -> str:
    """Get village status overview including cross-workspace agents."""
    # Update our heartbeat
    update_agent_heartbeat()
    
    # Get open issues count
    lst = await bd("list", "--status", "open")
    open_count = len(lst) if isinstance(lst, list) else 0
    
    # Get active reservations (local workspace)
    reservations = get_active_reservations()
    
    # Get agents across ALL workspaces
    all_agents = get_active_agents()
    workspaces = discover_workspaces()
    
    # Session duration
    mins = (datetime.now() - S.start).total_seconds() / 60
    
    return j({
        "agent": AGENT,
        "ws": WS,
        "team": TEAM,
        "open": open_count,
        "warn": open_count > 200,
        "current": S.issue,
        "reserved": len(S.reserved_files),
        "local_agents": len(set(r.get("agent", "") for r in reservations)),
        "team_agents": len(all_agents),
        "workspaces": len(workspaces),
        "min": round(mins, 1),
        "done": S.done
    })


# ============================================================================
# TOOL REGISTRY
# ============================================================================

TOOLS = {
    # Core workflow
    "init": {
        "fn": tool_init,
        "desc": "Join workspace. MUST call first. Returns agent ID, workspace, team.",
        "input": {
            "type": "object",
            "properties": {
                "ws": {"type": "string", "description": "Workspace path (default: cwd)"},
                "team": {"type": "string", "description": "Team name to join (default: 'default')"}
            },
            "required": []
        },
        "annotations": {"readOnlyHint": False, "destructiveHint": False, "idempotentHint": True, "openWorldHint": True}
    },
    "claim": {
        "fn": tool_claim,
        "desc": "Claim next ready task (highest priority). Auto-syncs, marks in_progress.",
        "input": {"type": "object", "properties": {}, "required": []},
        "annotations": {"readOnlyHint": False, "destructiveHint": False, "idempotentHint": False, "openWorldHint": True}
    },
    "done": {
        "fn": tool_done,
        "desc": "Complete task. Auto-releases files, syncs. Restart session after.",
        "input": {
            "type": "object",
            "properties": {
                "id": {"type": "string", "description": "Issue ID to close"},
                "msg": {"type": "string", "description": "What was done"}
            },
            "required": ["id"]
        },
        "annotations": {"readOnlyHint": False, "destructiveHint": False, "idempotentHint": True, "openWorldHint": True}
    },
    "add": {
        "fn": tool_add,
        "desc": "Create issue. Include desc for context.",
        "input": {
            "type": "object",
            "properties": {
                "title": {"type": "string", "description": "Actionable title"},
                "desc": {"type": "string", "description": "Why/what/how context"},
                "typ": {"type": "string", "description": "task|bug|feature|epic|chore"},
                "pri": {"type": "integer", "description": "0=critical,1=high,2=normal,3=low,4=backlog"},
                "deps": {"type": "array", "items": {"type": "string"}, "description": "type:id format"},
                "parent": {"type": "string", "description": "Parent issue ID"}
            },
            "required": ["title"]
        },
        "annotations": {"readOnlyHint": False, "destructiveHint": False, "idempotentHint": False, "openWorldHint": True}
    },
    # Issue queries
    "ls": {
        "fn": tool_ls,
        "desc": "List issues. Returns id,t,p,s per issue.",
        "input": {
            "type": "object",
            "properties": {
                "status": {"type": "string", "description": "open|closed|in_progress|all"},
                "limit": {"type": "integer", "description": "Max results (default:10)"},
                "offset": {"type": "integer", "description": "Skip N issues"}
            },
            "required": []
        },
        "annotations": {"readOnlyHint": True, "destructiveHint": False, "idempotentHint": True, "openWorldHint": True}
    },
    "ready": {
        "fn": tool_ready,
        "desc": "Get claimable tasks (no blockers). Sorted by priority.",
        "input": {
            "type": "object",
            "properties": {"limit": {"type": "integer", "description": "Max results (default:5)"}},
            "required": []
        },
        "annotations": {"readOnlyHint": True, "destructiveHint": False, "idempotentHint": True, "openWorldHint": True}
    },
    "show": {
        "fn": tool_show,
        "desc": "Get full issue details.",
        "input": {
            "type": "object",
            "properties": {"id": {"type": "string", "description": "Issue ID"}},
            "required": ["id"]
        },
        "annotations": {"readOnlyHint": True, "destructiveHint": False, "idempotentHint": True, "openWorldHint": True}
    },
    # Maintenance
    "cleanup": {
        "fn": tool_cleanup,
        "desc": "Remove old closed issues. Run every few days.",
        "input": {
            "type": "object",
            "properties": {"days": {"type": "integer", "description": "Delete closed >N days (default:2)"}},
            "required": []
        },
        "annotations": {"readOnlyHint": False, "destructiveHint": True, "idempotentHint": True, "openWorldHint": True}
    },
    "doctor": {
        "fn": tool_doctor,
        "desc": "Check/repair database health.",
        "input": {"type": "object", "properties": {}, "required": []},
        "annotations": {"readOnlyHint": False, "destructiveHint": False, "idempotentHint": True, "openWorldHint": True}
    },
    "sync": {
        "fn": tool_sync,
        "desc": "Sync with git. Pull/push changes.",
        "input": {"type": "object", "properties": {}, "required": []},
        "annotations": {"readOnlyHint": False, "destructiveHint": False, "idempotentHint": True, "openWorldHint": True}
    },
    # File reservations
    "reserve": {
        "fn": tool_reserve,
        "desc": "Lock files for editing. Prevents conflicts.",
        "input": {
            "type": "object",
            "properties": {
                "paths": {"type": "array", "items": {"type": "string"}, "description": "Files to lock"},
                "ttl": {"type": "integer", "description": "Seconds until expiry (default:600)"},
                "reason": {"type": "string", "description": "Why reserving"}
            },
            "required": ["paths"]
        },
        "annotations": {"readOnlyHint": False, "destructiveHint": False, "idempotentHint": False, "openWorldHint": False}
    },
    "release": {
        "fn": tool_release,
        "desc": "Unlock files. Auto-released on done().",
        "input": {
            "type": "object",
            "properties": {"paths": {"type": "array", "items": {"type": "string"}, "description": "Files to unlock (empty=all)"}},
            "required": []
        },
        "annotations": {"readOnlyHint": False, "destructiveHint": False, "idempotentHint": True, "openWorldHint": False}
    },
    "reservations": {
        "fn": tool_reservations,
        "desc": "List active file locks. Check before editing.",
        "input": {"type": "object", "properties": {}, "required": []},
        "annotations": {"readOnlyHint": True, "destructiveHint": False, "idempotentHint": True, "openWorldHint": False}
    },
    # Messaging
    "msg": {
        "fn": tool_msg,
        "desc": "Send message. Set global=true for cross-workspace.",
        "input": {
            "type": "object",
            "properties": {
                "subj": {"type": "string", "description": "Subject"},
                "body": {"type": "string", "description": "Message body"},
                "to": {"type": "string", "description": "Recipient or 'all'"},
                "thread": {"type": "string", "description": "Thread ID"},
                "importance": {"type": "string", "description": "low|normal|high"},
                "global": {"type": "boolean", "description": "Send to all workspaces"}
            },
            "required": ["subj"]
        },
        "annotations": {"readOnlyHint": False, "destructiveHint": False, "idempotentHint": False, "openWorldHint": False}
    },
    "inbox": {
        "fn": tool_inbox,
        "desc": "Get messages. Includes global by default.",
        "input": {
            "type": "object",
            "properties": {
                "n": {"type": "integer", "description": "Max messages (default:5)"},
                "unread": {"type": "boolean", "description": "Unread only"},
                "global": {"type": "boolean", "description": "Include cross-workspace"}
            },
            "required": []
        },
        "annotations": {"readOnlyHint": True, "destructiveHint": False, "idempotentHint": True, "openWorldHint": False}
    },
    "broadcast": {
        "fn": tool_broadcast,
        "desc": "Message all agents in team across workspaces.",
        "input": {
            "type": "object",
            "properties": {
                "subj": {"type": "string", "description": "Subject"},
                "body": {"type": "string", "description": "Message body"},
                "importance": {"type": "string", "description": "low|normal|high"}
            },
            "required": ["subj"]
        },
        "annotations": {"readOnlyHint": False, "destructiveHint": False, "idempotentHint": False, "openWorldHint": True}
    },
    "discover": {
        "fn": tool_discover,
        "desc": "Find active agents in team.",
        "input": {"type": "object", "properties": {}, "required": []},
        "annotations": {"readOnlyHint": True, "destructiveHint": False, "idempotentHint": True, "openWorldHint": True}
    },
    # Status
    "status": {
        "fn": tool_status,
        "desc": "Workspace overview: issues, task, agents, reservations.",
        "input": {"type": "object", "properties": {}, "required": []},
        "annotations": {"readOnlyHint": True, "destructiveHint": False, "idempotentHint": True, "openWorldHint": True}
    },
}


# ============================================================================
# MCP PROTOCOL HANDLER
# ============================================================================

async def handle_request(req: dict) -> Optional[dict]:
    """Handle JSON-RPC request."""
    method = req.get("method", "")
    params = req.get("params", {})
    req_id = req.get("id")
    
    if method == "initialize":
        return {
            "jsonrpc": "2.0",
            "id": req_id,
            "result": {
                "protocolVersion": "2024-11-05",
                "capabilities": {"tools": {}},
                "serverInfo": {"name": "beads-village", "version": "2.0"},
                "instructions": """Beads Village MCP - Multi-agent task coordination.

WORKFLOW: init()  claim()  reserve()  work  done()  restart session

RULES: init first | reserve before edit | add issues for >2min work

RESPONSE: id=ID, t=title, p=pri(0-4), s=status, f=from, b=body

TEAMS: init(team="x") to join | broadcast() for team-wide msgs"""
            }
        }
    
    elif method == "notifications/initialized":
        return None
    
    elif method == "tools/list":
        tools = []
        for k, v in TOOLS.items():
            tool_def = {
                "name": k,
                "description": v["desc"],
                "inputSchema": v["input"]
            }
            # Include annotations if present
            if "annotations" in v:
                tool_def["annotations"] = v["annotations"]
            tools.append(tool_def)
        return {"jsonrpc": "2.0", "id": req_id, "result": {"tools": tools}}
    
    elif method == "tools/call":
        name = params.get("name", "")
        args = params.get("arguments", {})

        if name in TOOLS:
            try:
                result = await TOOLS[name]["fn"](args)
                return {
                    "jsonrpc": "2.0",
                    "id": req_id,
                    "result": {
                        "content": [{"type": "text", "text": result}]
                    }
                }
            except Exception as e:
                return {
                    "jsonrpc": "2.0",
                    "id": req_id,
                    "result": {
                        "content": [{
                            "type": "text",
                            "text": j({
                                "error": str(e),
                                "hint": f"Tool '{name}' failed. Try 'doctor' to check workspace health."
                            })
                        }],
                        "isError": True
                    }
                }

        return {
            "jsonrpc": "2.0",
            "id": req_id,
            "error": {
                "code": -32601,
                "message": f"Unknown tool: {name}. Available tools: {', '.join(TOOLS.keys())}"
            }
        }

    elif method == "ping":
        return {"jsonrpc": "2.0", "id": req_id, "result": {}}
    
    return {
        "jsonrpc": "2.0",
        "id": req_id,
        "error": {"code": -32601, "message": f"Unknown method: {method}"}
    }


def run_server():
    """Run MCP server on stdio."""
    import warnings
    warnings.filterwarnings("ignore")
    
    # Windows binary mode
    if sys.platform == "win32":
        import msvcrt
        msvcrt.setmode(sys.stdin.fileno(), os.O_BINARY)
        msvcrt.setmode(sys.stdout.fileno(), os.O_BINARY)
    
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    
    try:
        while True:
            line = sys.stdin.buffer.readline()
            if not line:
                break
            
            try:
                req = json.loads(line.decode().strip())
            except json.JSONDecodeError:
                continue
            
            resp = loop.run_until_complete(handle_request(req))
            
            if resp:
                out = json.dumps(resp) + "\n"
                sys.stdout.buffer.write(out.encode())
                sys.stdout.buffer.flush()
    finally:
        loop.run_until_complete(loop.shutdown_asyncgens())
        loop.close()


def main():
    run_server()


if __name__ == "__main__":
    main()
